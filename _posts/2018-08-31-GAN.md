---
layout:     post   				    # 使用的布局
title:      28.0 生成对抗网络 				# 标题 
date:       2018-08-31 				# 时间
author:     子颢 						# 作者
catalog: true 						# 是否归档
tags:								#标签
    - 深度学习
    - GAN
    - 生成对抗网络
---

# 算法原理

GAN，生成对抗网络，该模型主要包含两个核心模块：一个是判别器，一个是生成器。比如，我们有一批真实数据，同时也有一批随机生成的假数据，生成器A拼命地把随手拿过来的假数据模仿成真实数据，并揉进真实数据里，判别器B则拼命地想把真实数据和假数据区分开。A类似于造假币的，B类似于稽查警察，A一个劲地学习如何骗过B，而B则是一个劲地学习如何分辨出A的造假技巧。如此这般，随着B的鉴别技巧的越来越厉害，A的造假技巧也是越来越纯熟，而一个一流的假币制造者就是我们所需要的。这就是GAN背后的思想，十分的直观与朴素。

![GAN](/img/GAN-01.png)
1. GAN的目标是令生成器生成与真实数据几乎没有区别的样本，数学上来讲即将随机变量生成为某一种概率分布，该分布的概率密度函数等于真实数据的概率密度函数，即P_G(x)=P_data(x)。为了学习到生成器G在数据X上的分布P_G，我们先定义一个先验的输入噪声变量z，然后根据G(z)将其映射到数据空间X中，然后再定义一个判别器D，它的输出为单个标量。D(x)表示x来源于真实数据而不是P_G的概率。
2. E指取期望，其实也就是极大似然估计，最大化加号前一项相当于令判别器D在X服从data的概率密度时能准确地预测D(x)=1，对于D而言要尽量使价值函数V(D,G)最大化（识别能力强），而对于G而言，又想使之最小（生成的数据接近实际数据）。
3. 整个训练是一个不断迭代的过程，即在给定G的情况下先最大化V(D,G)而训练D，当D有了一定的辨别能力后，固定D，然后最小化V(D,G)而训练G。
4. 迭代的固定其中一个，训练另一个（一般D训练K步后才训练G一次），最终模型会到达一个均衡点，这个时候生成器的概率密度函数等于真实数据的概率密度函数，也即生成的数据和真实数据是一样的，在均衡点上D和G都不能得到进一步提升，并且判别器无法判断数据到底是来自真实样本还是伪造的数据，即D(x)=1/2。

总地来说，GAN是通过对抗过程估计生成模型的新框架。即我们需要同时训练两个模型，一个能捕获数据分布的生成模型G和一个能估计数据来源于真实样本概率的判别模型D。生成器G的训练过程是最大化判别器犯错误的概率，即判别器误以为数据是真实样本而不是生成器生成的假样本。因此，这一框架就对应于两个参与者的极小极大博弈（minimax game）。在所有可能的函数G和D中，我们可以求出唯一均衡解，即G可以生成与训练样本相同的分布，而D判断的概率处处为1/2。

# 代码实现

```

```

# 社群

- QQ交流群
	![562929489](/img/qq_ewm.png)
- 微信交流群
	![562929489](/img/wx_ewm.png)
- 微信公众号
	![562929489](/img/wxgzh_ewm.png)