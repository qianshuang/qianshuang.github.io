---
layout:     post   				    # 使用的布局
title:      46.0 目标检测			# 标题 
date:       2018-11-20 				# 时间
author:     子颢 						# 作者
catalog: true 						# 是否归档
tags:								# 标签
    - 计算机视觉
    - 目标检测
---

目标检测（Object Detection），就是在给定的图片中精确找到物体所在位置（方框框出它的位置），并标注出物体的类别。object detection技术的演进：RCNN->Fast RCNN->Faster RCNN。
![OD](/img/OD-01.png)

# RCNN

RCNN（Region CNN）,是最古老也是最经典的基于深度学习的目标检测算法，该算法使用Selective Search方法预先从图片（训练数据）中提取一系列较可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断。RCNN算法主要分为4个步骤：
1. 从训练数据图像中生成1K~2K个候选区域（region proposals）。
2. 对每个候选区域，使用CNN提取特征。
3. 将提取到的特征送入SVM分类器，判断所属类别。
4. 使用回归器精细修正候选框位置。
![OD](/img/OD-02.png)
注：训练数据一共包含10000张图像，一共20个类别，每张图片中，标注物体的类别和位置。
下面我们依次来看一看每一步具体是怎么做的。

## 候选区域生成

候选区域生成使用了Selective Search方法从一张图像中生成1000~2000个候选区域，基本思路如下：
1. 使用一种过分割手段，将图像分割成一个个小region。
2. 采用类似于层次聚类的方法依次合并吻合度最高的两个region。
3. 输出聚合后的所有region（即得到RoI，Region of Interests）。
注：候选区域生成步骤相对独立，可以使用任意算法进行，只不过Selective Search算法最为常用。

## 特征提取

1. 预处理。提取特征之前，首先把所有候选区域归一化成同一尺寸，比如227×227。
2. 采用Image Net或经典的ResNet训练分类模型。训练数据一共有21个label（20个物体label加1个背景label），考察每一个候选区域和当前图像上的所有标注框的重叠面积，如果重叠比例大于0.5，则认为此候选区域为此标注的类别，否则认为此候选区域为背景。
3. 对每个候选区域，输入到2步中的CNN网络中，取倒数第二层的输出（4096维）作为特征表示。

## 类别判断

1. 对每一个类别，训练一个线性SVM二分类器。
2. 输入为特征提取步所输出的4096维特征表示，输出是否属于此类（0或1）。
3. 对于每一个类别（对应每一个不同的SVM二分类器），考察每一个候选区域，如果和本类所有标注框的重叠都小于0.3，认定其为负样本，取本类的标注区域作为正样本。
4. 由于负样本很多，使用hard negative mining方法进行下采样。
注：把特征提取和类别判断拆成两步来做，相当于做了一次stack ensemble。

## 位置精修

训练一个线性回归模型精细修正候选框位置。训练样本为所有和真值标注重叠面积大于0.6的候选区域，输入为特征提取步所得到的4096维特征表示，输出为xy方向上的缩放和平移（一维向量得到一个回归值，两列矩阵即可得到两个回归值）。

# Fast RCNN









参考资料：
- <a href="https://github.com/vipstone/faceai" target="_blank">vipstone_faceai</a>
- <a href="http://tumumu.cn/2017/05/02/deep-learning-face/" target="_blank">deep-learning-face</a>

# 社群

- 微信公众号
	![562929489](/img/wxgzh_ewm.png)